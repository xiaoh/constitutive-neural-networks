{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# system modules\n",
    "import os\n",
    "import time\n",
    "from pathlib import Path\n",
    "from IPython.display import display, Math\n",
    "\n",
    "# scientific computing\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "import pandas as pd\n",
    "np.random.seed(42)\n",
    "from fipy import CellVariable,PeriodicGrid2D, Grid2D\n",
    "from fipy import DiffusionTerm, ExponentialConvectionTerm, DefaultAsymmetricSolver, ImplicitSourceTerm\n",
    "from fipy import MatplotlibStreamViewer\n",
    "from fipy.tools.numerix import array, reshape\n",
    "\n",
    "# plotting\n",
    "import matplotlib\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "import plotly.graph_objs as go\n",
    "import plotly.io as pio\n",
    "from plotly import subplots\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "# pytorch importing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torch.optim import lr_scheduler, Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taylor Green Vortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vortex():\n",
    "    vortex_u = np.zeros([Ny,Nx])\n",
    "    vortex_v = np.zeros([Ny,Nx])\n",
    "    for i in range(0,Ny):\n",
    "        for j in range(0,Nx):\n",
    "            vortex_u[i][j] = V_0*np.sin((2*np.pi/Lx)*(j+0.5)*dx)*np.cos((2*np.pi/Ly)*(Ny-0.5-i)*dy)\n",
    "            vortex_v[i][j] = -1*V_0*np.cos((2*np.pi/Lx)*(j+0.5)*dx)*np.sin((2*np.pi/Ly)*(Ny-0.5-i)*dy)\n",
    "            \n",
    "    vortex_u = vortex_u.flatten()\n",
    "    vortex_v = vortex_v.flatten()\n",
    "    \n",
    "    return vortex_u,vortex_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Velocity Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_vel(mesh):\n",
    "    vel = mesh.cellCenters.copy()\n",
    "    vel.name = 'Velocity'\n",
    "    u,v = vortex()\n",
    "    vel.value[0] = u\n",
    "    vel.value[1] = v\n",
    "    return vel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strain_rate_mag():\n",
    "    strain = np.zeros([Ny,Nx])\n",
    "    for i in range(0,Ny):\n",
    "        for j in range(0,Nx):\n",
    "            strain[i][j] = np.abs(4*np.pi*V_0/Lx*np.cos((2*np.pi/Lx)*(j+0.5)*dx)*np.cos((2*np.pi/Ly)*(Ny-0.5-i)*dy))\n",
    "\n",
    "    return strain/(4*np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spin Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotation_mag():\n",
    "    omega = np.zeros([Ny,Nx])\n",
    "    for i in range(0,Ny):\n",
    "        for j in range(0,Nx):\n",
    "            omega[i][j] = np.abs(4*np.pi*V_0/Lx*np.sin((2*np.pi/Lx)*(j+0.5)*dx)*np.sin((2*np.pi/Ly)*(Ny-0.5-i)*dy))\n",
    "            \n",
    "    return omega"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strain Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_stra(mesh):\n",
    "    stra = CellVariable(name='Strain', mesh=mesh)   \n",
    "    strain_matrix = strain_rate_mag()\n",
    "    stra.value = strain_matrix.flatten()\n",
    "    \n",
    "    return stra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rota(mesh):\n",
    "    rota = CellVariable(name='Rotation', mesh=mesh)   \n",
    "    rota_matrix = rotation_mag()\n",
    "    rota.value = rota_matrix.flatten()\n",
    "    \n",
    "    return rota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_src(mesh):\n",
    "    src = CellVariable(name='Production', mesh=mesh)\n",
    "    \n",
    "    strain = strain_rate_mag()\n",
    "    rota = rotation_mag()\n",
    "    src_matrix = src.value.reshape(Ny,Nx)\n",
    "    src_matrix = (1/(1+rota**2))*(4*np.sin(2*np.pi*strain)+6*strain**2+5*np.exp(strain)) # production function\n",
    "    src.value = src_matrix.flatten()\n",
    "    \n",
    "    return src "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data_Concentrations Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_cdr_pde(mesh, diff_coeff, diss_coeff):\n",
    "    data_list = []\n",
    "    array_list = []\n",
    "    var = CellVariable(name='Variable',mesh=mesh)\n",
    "    vel = sample_vel(mesh)\n",
    "    stra = sample_stra(mesh)\n",
    "    rota = sample_rota(mesh)\n",
    "    src = compute_src(mesh)\n",
    "    eq = - ExponentialConvectionTerm(coeff=vel) + DiffusionTerm(coeff=diff_coeff) - ImplicitSourceTerm(diss_coeff) + src\n",
    "    eq.solve(var=var, solver=DefaultAsymmetricSolver(tolerance=1.e-12, iterations=10000))\n",
    "    data = {'var': var, 'src': src, 'vel': vel, 'stra': stra, 'rota': rota, 'diff': diff_coeff, 'diss': diss_coeff}\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic(array):  # dimension of array => [Ny,Nx]\n",
    "    peri_num_x = 2*(int(N*h/Lx)+1)+1\n",
    "    peri_num_y = 2*(int(N*h/Ly)+1)+1\n",
    "    peri = np.zeros((peri_num_y*Ny,peri_num_x*Nx))\n",
    "    for i in range(0,Ny*(peri_num_y-1)+1,Ny):\n",
    "        for j in range(0,Nx*(peri_num_x-1)+1,Nx):\n",
    "            peri[i:i+Ny,j:j+Nx] = array\n",
    "    return peri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Network, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=2, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=8, out_channels=4, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=4, out_channels=1, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(2,32)\n",
    "        self.fc2 = nn.Linear(32,16)\n",
    "        self.fc3 = nn.Linear(16,8)\n",
    "        self.fc4 = nn.Linear(8,4)\n",
    "        self.fc5 = nn.Linear(4,1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, X):\n",
    "        X1 = X[:,0:2,:,:]\n",
    "        X2 = X[:,2:3,:,:]\n",
    "        X3 = X[:,3:4,:,:]\n",
    "        \n",
    "        out = self.relu(self.conv1(X1))\n",
    "        out = self.relu(self.conv2(out))\n",
    "        out = self.relu(self.conv3(out))\n",
    "        out = self.relu(self.conv4(out))\n",
    "        out = self.relu(self.conv5(out))\n",
    "        G = self.conv6(out)\n",
    "        \n",
    "        dim1 = X.size()[0]\n",
    "        dim3 = X.size()[2]\n",
    "        \n",
    "        X2 = X2.reshape(-1,1)\n",
    "        X3 = X3.reshape(-1,1)\n",
    "        X4 = torch.cat((X2,X3),1)\n",
    "        \n",
    "        X4_out = self.relu(self.fc1(X4))\n",
    "        X4_out = self.relu(self.fc2(X4_out))\n",
    "        X4_out = self.relu(self.fc3(X4_out))\n",
    "        X4_out = self.relu(self.fc4(X4_out))\n",
    "        X4_out = self.fc5(X4_out)\n",
    "        P = X4_out.reshape(dim1,-1,dim3,dim3)\n",
    "        \n",
    "        Init1 = torch.zeros([dim1,1,dim3,dim3],device=device)\n",
    "        Init2 = torch.addcmul(Init1,1, G, P)\n",
    "        c = torch.sum(torch.sum(Init2,dim=3),dim=2)\n",
    "        c = c.reshape(dim1,1)\n",
    "        \n",
    "        return G,P,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, valid_loader, num_epoch):\n",
    "    train_err_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    valid_err_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    train_loss_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "    valid_loss_hist = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "\n",
    "    for epoch in range(num_epoch+1):\n",
    "        train_loss_array = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        train_err_rate_num = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        train_err_rate_den = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_loss_array = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_err_rate_num = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "        valid_err_rate_den = torch.cuda.FloatTensor(1,1).fill_(0)\n",
    "\n",
    "        for i, data in enumerate(train_loader):\n",
    "            features, target = data\n",
    "            optimizer.zero_grad()\n",
    "            G_train, P_train, forward = model(features)\n",
    "            loss = loss_fn(forward, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss_array = torch.cat((train_loss_array, torch.cuda.FloatTensor([[loss.item()]])))\n",
    "            train_err_num, train_err_den = report_err_rate(target, forward)\n",
    "            train_err_rate_num = torch.cat((train_err_rate_num, (train_err_num.view(1,-1))**2), 0)\n",
    "            train_err_rate_den = torch.cat((train_err_rate_den, (train_err_den.view(1,-1))**2), 0)\n",
    "\n",
    "        train_loss = torch.mean(train_loss_array)\n",
    "        train_err_rate = 100*((torch.sum(train_err_rate_num, 0))**0.5)/((torch.sum(train_err_rate_den, 0))**0.5)\n",
    "\n",
    "        exp_lr_scheduler.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i, data_valid in enumerate(valid_loader):\n",
    "                features_valid, target_valid = data_valid\n",
    "                G_valid, P_valid, forward_valid = model(features_valid)\n",
    "                pred_loss = loss_fn(forward_valid, target_valid)\n",
    "\n",
    "                valid_loss_array = torch.cat((valid_loss_array, torch.cuda.FloatTensor([[loss.item()]])))\n",
    "                valid_err_num, valid_err_den = report_err_rate(target_valid, forward_valid)\n",
    "                valid_err_rate_num = torch.cat((valid_err_rate_num, (valid_err_num.view(1,-1))**2), 0)\n",
    "                valid_err_rate_den = torch.cat((valid_err_rate_den, (valid_err_den.view(1,-1))**2), 0)\n",
    "\n",
    "            valid_loss = torch.mean(valid_loss_array)\n",
    "            valid_err_rate = 100*((torch.sum(valid_err_rate_num, 0))**0.5)/((torch.sum(valid_err_rate_den, 0))**0.5)\n",
    "\n",
    "        verb = True if (epoch >= 50) and (epoch % 10 == 0) else False\n",
    "        if (verb):\n",
    "            train_loss_hist = torch.cat((train_loss_hist, torch.cuda.FloatTensor([[train_loss]])))\n",
    "            train_err_hist = torch.cat((train_err_hist, train_err_rate.view(1,-1)), 0)\n",
    "            valid_loss_hist = torch.cat((valid_loss_hist, torch.cuda.FloatTensor([[valid_loss]])))\n",
    "            valid_err_hist = torch.cat((valid_err_hist, valid_err_rate.view(1,-1)), 0)\n",
    "        verb = True if (epoch % 50 == 0) else False\n",
    "        if (verb) :\n",
    "            print('{:4}   lr: {:.2e}   train_loss: {:.2e}   valid_loss: {:.2e}   train_error:{:7.2f}%   valid_error:{:7.2f}%' \\\n",
    "                  .format(epoch, exp_lr_scheduler.get_lr()[0], train_loss, valid_loss, train_err_rate[0], valid_err_rate[0]))\n",
    "            \n",
    "    print('Finished Training')\n",
    "    return train_loss_hist, train_err_hist, valid_loss_hist, valid_err_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_err_rate(target, forward):\n",
    "    errRate_sigma_num = torch.norm(forward - target, dim = 0)\n",
    "    errRate_sigma_den = torch.norm(target, dim = 0)\n",
    "    return errRate_sigma_num, errRate_sigma_den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_plot(training_loss_history, training_error_history, valid_loss_history, valid_error_history):\n",
    "    \n",
    "    data1 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=training_loss_history[1:,0], line = dict(width=1.7), name = 'Training Loss', mode = 'lines')\n",
    "    data2 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=valid_loss_history[1:,0], line = dict(width=1.7), name = 'Validation Loss', mode = 'lines')\n",
    "    data3 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=training_error_history[1:,0], line = dict(width=1.7), name = 'Training Error', mode = 'lines')\n",
    "    data4 = go.Scatter(x=np.arange(50,num_epoch+1,10), y=valid_error_history[1:,0], line = dict(width=1.7), name = 'Validation Error', mode = 'lines')\n",
    "    \n",
    "    fig = subplots.make_subplots(rows=1, cols=2)\n",
    "    fig.append_trace(data1, 1, 1)\n",
    "    fig.append_trace(data2, 1, 1)\n",
    "    fig.append_trace(data3, 1, 2)\n",
    "    fig.append_trace(data4, 1, 2)\n",
    "    \n",
    "    fig['layout']['xaxis1'].update(title='Epochs', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['yaxis1'].update(title='Loss', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['xaxis2'].update(title='Epochs', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout']['yaxis2'].update(title='Error %', showgrid=True, gridwidth=0.5, gridcolor='lightgrey', showline=True, linecolor='black')\n",
    "    fig['layout'].update(height=450, width=1000, plot_bgcolor = 'rgba(0,0,0,0)', title='Loss and Error Percentage History')\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_valid(nn_target,nn_output, title):\n",
    "\n",
    "    data1 = go.Scatter(x=nn_target[:,0].numpy(), y=nn_output[:,0].numpy(), mode='markers', \n",
    "                       marker=dict(color='rgb(158, 22, 25)', size=7, opacity=0.3,\n",
    "                                     line=dict(width=1)), showlegend=True , name='NN')\n",
    "    \n",
    "    line_min = np.array([nn_target[:,0].numpy().min(), nn_output[:,0].numpy().min()]).min()\n",
    "    line_max = np.array([nn_target[:,0].numpy().max(), nn_output[:,0].numpy().max()]).max()\n",
    "    data2 = go.Scatter(x=np.linspace(line_min,line_max,10), y=np.linspace(line_min,line_max, 10), mode='lines', \n",
    "                       line=dict(width=1.7, color='black'), showlegend=False)\n",
    "\n",
    "    layout = go.Layout(title=title, \n",
    "                       xaxis=dict(title='Truth', range=[line_min, line_max], showgrid=False, showline=True, linecolor='black', zeroline=False, mirror='ticks'),\n",
    "                       yaxis=dict(title='Prediction', range=[line_min, line_max], showgrid=False, showline=True, linecolor='black', zeroline=False, mirror='ticks'),\n",
    "                       width=600, height=570, plot_bgcolor = 'rgba(0,0,0,0)')\n",
    "    \n",
    "    fig = go.Figure(data=[data1,data2], layout=layout)\n",
    "    iplot(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_cell(var):\n",
    "    fig, axes = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    axes.set_title('{}'.format(var.name))\n",
    "    axes.set_xlabel('x')\n",
    "    axes.set_ylabel('y')\n",
    "    cmap = matplotlib.cm.jet\n",
    "    xmin, ymin = var.mesh.extents['min']\n",
    "    xmax, ymax = var.mesh.extents['max']\n",
    "    data = reshape(array(var), var.mesh.shape[::-1])[::-1]\n",
    "    img = axes.imshow(data, extent=(xmin, xmax, ymin, ymax), cmap=cmap)\n",
    "    plt.colorbar(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device=torch.device('cuda:1')\n",
    "else:\n",
    "    device=torch.device('cpu')\n",
    "\n",
    "device_cpu = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source field = calculation domain\n",
    "dx = 0.01; dy = 0.01\n",
    "Nx = 100; Ny = 100\n",
    "Lx = dx*Nx; Ly = dy*Ny\n",
    "mesh = PeriodicGrid2D(dx=dx, dy=dy, nx=Nx, ny=Ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=2e-1\n",
    "n=3\n",
    "N=1.5 # N = max(D/2h)\n",
    "cells=np.array([[-5,-4,-3,-2,-1,0,1,2,3,4,5]])\n",
    "cells_x=np.repeat(cells,cells.shape[1],axis=0)\n",
    "cells_y=np.repeat(cells.T,cells.shape[1],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 3a: Training and Validation data from different flow cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation - Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples_valid=5\n",
    "\n",
    "\n",
    "for sample in range(num_samples_valid):\n",
    "    # PDE coefficients\n",
    "#     diff_coeff = np.random.uniform(low=0.01, high=0.1)     # Diffusion Coefficient\n",
    "#     diss_coeff = np.random.uniform(low=10, high=15)     # Dissipation Coefficient\n",
    "    \n",
    "    diff_coeff = 0.02\n",
    "    diss_coeff = 20\n",
    "    \n",
    "    C_max = 1.0  # the maximum value of the velocity\n",
    "    V_0 = np.random.uniform(low=C_max*0.05, high=C_max)\n",
    "\n",
    "    \n",
    "    data_3_valid = solve_cdr_pde(mesh, diff_coeff, diss_coeff)\n",
    "    \n",
    "    lambda1=(C_max - (((C_max**2)+(4*diff_coeff*diss_coeff))**0.5)) / (2*diff_coeff)\n",
    "    h=np.abs(np.log(epsilon)/lambda1)   # h => maximum h\n",
    "    \n",
    "    print('diff     diss     h      V_0')\n",
    "    print('{:.3f}   {:.3f}   {:.3f}   {:.3f}'.format(diff_coeff,diss_coeff,h,V_0))\n",
    "    view_cell(data_3_valid['stra'])\n",
    "    view_cell(data_3_valid['rota'])\n",
    "    view_cell(data_3_valid['src'])\n",
    "    view_cell(data_3_valid['var'])\n",
    "    \n",
    "    c_data_valid_mesh_3 = reshape(array(data_3_valid['var']), data_3_valid['var'].mesh.shape[::-1])\n",
    "    s_data_valid_mesh_3 = reshape(array(data_3_valid['stra']), data_3_valid['stra'].mesh.shape[::-1])\n",
    "    r_data_valid_mesh_3 = reshape(array(data_3_valid['rota']), data_3_valid['rota'].mesh.shape[::-1])\n",
    "    u_data_valid_mesh_3 = reshape(array(data_3_valid['vel'])[0,:], data_3_valid['vel'].mesh.shape[::-1])\n",
    "    v_data_valid_mesh_3 = reshape(array(data_3_valid['vel'])[1,:], data_3_valid['vel'].mesh.shape[::-1])\n",
    "    \n",
    "    # add local noise to c field\n",
    "#     for i in range(0,Ny):\n",
    "#         for j in range(0,Nx):\n",
    "#             c_data_valid_mesh_3[i][j] += np.random.normal(loc=0.0,scale=noise_level*c_data_valid_mesh_3[i][j])\n",
    "    \n",
    "#     print(c_data_valid_mesh_3.shape)\n",
    "#     print(type(u_data_valid_mesh_3))\n",
    "    \n",
    "    periodic_c_valid = periodic(c_data_valid_mesh_3)\n",
    "    periodic_s_valid = periodic(s_data_valid_mesh_3)\n",
    "    periodic_r_valid = periodic(r_data_valid_mesh_3)\n",
    "    periodic_u_valid = periodic(u_data_valid_mesh_3)\n",
    "    periodic_v_valid = periodic(v_data_valid_mesh_3)\n",
    "    \n",
    "#     print(periodic_c_valid.shape)\n",
    "    \n",
    "    dataX_valid_current=np.empty([c_data_valid_mesh_3.shape[0]*c_data_valid_mesh_3.shape[1], 4, cells.shape[1], cells.shape[1]])\n",
    "    dataY_valid_current=np.empty([c_data_valid_mesh_3.shape[0]*c_data_valid_mesh_3.shape[1], 1])\n",
    "    \n",
    "#     print(dataX_valid_current.shape)\n",
    "#     print(dataY_valid_current.shape)\n",
    "    \n",
    "    data_ind=0\n",
    "    for i in range(Ny*(int(N*h/Ly)+1),Ny*(int(N*h/Ly)+2)):\n",
    "        for j in range(Nx*(int(N*h/Lx)+1),Nx*(int(N*h/Lx)+2)):\n",
    "            dataX_valid_current[data_ind,0,:,:]=periodic_u_valid[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_valid_current[data_ind,1,:,:]=periodic_v_valid[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_valid_current[data_ind,2,:,:]=periodic_s_valid[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_valid_current[data_ind,3,:,:]=periodic_r_valid[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataY_valid_current[data_ind,0]=periodic_c_valid[i,j]\n",
    "            data_ind+=1\n",
    "    \n",
    "    dataX_valid_current=torch.tensor(dataX_valid_current).to(dtype=torch.float)\n",
    "    dataY_valid_current=torch.tensor(dataY_valid_current).to(dtype=torch.float)\n",
    "    \n",
    "    if sample<1:\n",
    "        dataX_valid=dataX_valid_current\n",
    "        dataY_valid=dataY_valid_current\n",
    "    else:\n",
    "        dataX_valid=torch.cat((dataX_valid,dataX_valid_current))\n",
    "        dataY_valid=torch.cat((dataY_valid,dataY_valid_current))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generation - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_samples=100\n",
    "\n",
    "\n",
    "for sample in range(num_samples):\n",
    "    # PDE coefficients\n",
    "#     diff_coeff = np.random.uniform(low=0.01, high=0.1)     # Diffusion Coefficient\n",
    "#     diss_coeff = np.random.uniform(low=10, high=15)     # Dissipation Coefficient\n",
    "    \n",
    "    diff_coeff = 0.02\n",
    "    diss_coeff = 20\n",
    "    \n",
    "    C_max = 1.0  # the maximum value of the velocity\n",
    "    V_0 = np.random.uniform(low=C_max*0.05, high=C_max)   # velocity range (0,1)\n",
    "    \n",
    "    data_3 = solve_cdr_pde(mesh, diff_coeff, diss_coeff)\n",
    "    \n",
    "    lambda1=(C_max - (((C_max**2)+(4*diff_coeff*diss_coeff))**0.5)) / (2*diff_coeff)\n",
    "    h=np.abs(np.log(epsilon)/lambda1)   # h => maximum h\n",
    "    \n",
    "    c_data_mesh_3 = reshape(array(data_3['var']), data_3['var'].mesh.shape[::-1])\n",
    "    s_data_mesh_3 = reshape(array(data_3['stra']), data_3['stra'].mesh.shape[::-1])\n",
    "    r_data_mesh_3 = reshape(array(data_3['rota']), data_3['rota'].mesh.shape[::-1])\n",
    "    u_data_mesh_3 = reshape(array(data_3['vel'])[0,:], data_3['vel'].mesh.shape[::-1])\n",
    "    v_data_mesh_3 = reshape(array(data_3['vel'])[1,:], data_3['vel'].mesh.shape[::-1])\n",
    "    \n",
    "    \n",
    "    periodic_c = periodic(c_data_mesh_3)\n",
    "    periodic_s = periodic(s_data_mesh_3)\n",
    "    periodic_r = periodic(r_data_mesh_3)\n",
    "    periodic_u = periodic(u_data_mesh_3)\n",
    "    periodic_v = periodic(v_data_mesh_3)\n",
    "    \n",
    "    dataX_train_current=np.empty([c_data_mesh_3.shape[0]*c_data_mesh_3.shape[1], 4, cells.shape[1], cells.shape[1]])\n",
    "    dataY_train_current=np.empty([c_data_mesh_3.shape[0]*c_data_mesh_3.shape[1], 1])\n",
    "    \n",
    "\n",
    "    data_ind=0\n",
    "    for i in range(Ny*(int(N*h/Ly)+1),Ny*(int(N*h/Ly)+2)):\n",
    "        for j in range(Nx*(int(N*h/Lx)+1),Nx*(int(N*h/Lx)+2)):\n",
    "            dataX_train_current[data_ind,0,:,:]=periodic_u[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_train_current[data_ind,1,:,:]=periodic_v[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_train_current[data_ind,2,:,:]=periodic_s[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataX_train_current[data_ind,3,:,:]=periodic_r[(cells_y*n)+i,(cells_x*n)+j]\n",
    "            dataY_train_current[data_ind,0]=periodic_c[i,j]\n",
    "            data_ind+=1\n",
    "    \n",
    "    dataX_train_current=torch.tensor(dataX_train_current).to(dtype=torch.float)\n",
    "    dataY_train_current=torch.tensor(dataY_train_current).to(dtype=torch.float)\n",
    "    \n",
    "    if sample<1:\n",
    "        dataX_train=dataX_train_current\n",
    "        dataY_train=dataY_train_current\n",
    "    else:\n",
    "        dataX_train=torch.cat((dataX_train,dataX_train_current))\n",
    "        dataY_train=torch.cat((dataY_train,dataY_train_current))\n",
    "        \n",
    "    print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduc_data_size = int(dataX_train.shape[0] * (50/num_samples))\n",
    "ind = list(range(dataX_train.shape[0]))\n",
    "np.random.shuffle(ind)\n",
    "train_ind = ind[:reduc_data_size]\n",
    "dataX_train = dataX_train[train_ind]\n",
    "dataY_train = dataY_train[train_ind]\n",
    "print('Reduced Training Data Size: {}   {}'.format(dataX_train.shape, dataY_train.shape))\n",
    "print('Validation Data Size:       {}   {}'.format(dataX_valid.shape, dataY_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX_train = dataX_train.to(device)\n",
    "dataY_train = dataY_train.to(device)\n",
    "dataX_valid = dataX_valid.to(device)\n",
    "dataY_valid = dataY_valid.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating datasets\n",
    "dataset_train = TensorDataset(dataX_train,dataY_train)\n",
    "dataset_valid = TensorDataset(dataX_valid,dataY_valid)\n",
    "\n",
    "#creating batches from dataset\n",
    "batch_size_train = 1024          #int(dataX_train.shape[0]/20) + 1\n",
    "batch_size_valid = dataX_valid.shape[0]\n",
    "\n",
    "train_loader = DataLoader(dataset = dataset_train, batch_size=batch_size_train, shuffle=True)\n",
    "valid_loader = DataLoader(dataset = dataset_valid, batch_size=batch_size_valid, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "model = CNN_Network()\n",
    "model.to(device)\n",
    "loss_fn = nn.MSELoss(reduction='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "para_count = count_parameters(model)\n",
    "print('Total Learnable Parameters: {}'.format(para_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "num_epoch = 500\n",
    "learning_rate = 1e-3\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=600, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "training_loss_history, training_error_history, valid_loss_history, valid_error_history = train(train_loader, valid_loader, num_epoch)\n",
    "elapsed = time.time() - start_time                \n",
    "print('Training time: %.1f s' % (elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'TG_learning-P_gpu.pt')  # 1-1 --> num of case_fixed/unfixed\n",
    "model.to(device_cpu)\n",
    "torch.save(model, 'TG_learning-P_cpu.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss_history = training_loss_history.to(device_cpu)\n",
    "training_error_history = training_error_history.to(device_cpu)\n",
    "valid_loss_history = valid_loss_history.to(device_cpu)\n",
    "valid_error_history = valid_error_history.to(device_cpu)\n",
    "error_plot(training_loss_history.detach().numpy(), training_error_history.detach().numpy(), valid_loss_history.detach().numpy(), valid_error_history.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for i, nn_data in enumerate(valid_loader):\n",
    "#         nn_features, nn_target = nn_data\n",
    "#         G_output, nn_output = model(nn_features)\n",
    "\n",
    "# nn_output = nn_output.to(device_cpu)\n",
    "# nn_target = nn_target.to(device_cpu)\n",
    "# title = 'Validation'\n",
    "# plot_valid(nn_target,nn_output,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
